{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71642330-94af-4da0-b342-00bc8cbf3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "import mnist_model  # ADDED\n",
    "# REMOVED from experimental.mimo import cifar_model  # local file import\n",
    "import robustness_metrics as rm\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import uncertainty_baselines as ub\n",
    "import baselines.utils_new as utils  # ADDED this!\n",
    "# from uncertainty_baselines.baselines.cifar import utils\n",
    "import uncertainty_metrics as um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e36df92-ebf3-4ee2-a1cd-35c9776b7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flags.DEFINE_integer('ensemble_size', 6, 'Size of ensemble.')\n",
    "flags.DEFINE_float('input_repetition_probability', 0.0,\n",
    "                   'The probability that the inputs are identical for the'\n",
    "                   'ensemble members.')\n",
    "flags.DEFINE_integer('width_multiplier', 2, 'Integer to multiply the number of'\n",
    "                                             'typical filters by. \"k\" in ResNet-n-k.')\n",
    "flags.DEFINE_integer('per_core_batch_size', 128, 'Batch size per TPU core/GPU.')\n",
    "flags.DEFINE_integer('batch_repetitions', 4, 'Number of times an example is'\n",
    "                                             'repeated in a training batch. More repetitions lead to'\n",
    "                                             'lower variance gradients and increased training time.')\n",
    "flags.DEFINE_integer('seed', 0, 'Random seed.')\n",
    "flags.DEFINE_float('base_learning_rate', 0.1,\n",
    "                   'Base learning rate when total training batch size is 128.')\n",
    "flags.DEFINE_integer(\n",
    "    'lr_warmup_epochs', 1,\n",
    "    'Number of epochs for a linear warmup to the initial '\n",
    "    'learning rate. Use 0 to do no warmup.')\n",
    "flags.DEFINE_float('lr_decay_ratio', 0.2, 'Amount to decay learning rate.')\n",
    "flags.DEFINE_list('lr_decay_epochs', ['80', '160', '180'],\n",
    "                  'Epochs to decay learning rate by.')\n",
    "flags.DEFINE_float('l2', 3e-4, 'L2 coefficient.')\n",
    "flags.DEFINE_enum(\n",
    "    'dataset', 'mnist', enum_values=['cifar10', 'cifar100', 'mnist'], help='Dataset.')\n",
    "# TODO(ghassen): consider adding CIFAR-100-C to TFDS.\n",
    "flags.DEFINE_string(\n",
    "    'cifar100_c_path', '',\n",
    "    'Path to the TFRecords files for CIFAR-100-C. Only valid '\n",
    "    '(and required) if dataset is cifar100 and corruptions.')\n",
    "flags.DEFINE_integer(\n",
    "    'corruptions_interval', 50,\n",
    "    'Number of epochs between evaluating on the corrupted '\n",
    "    'test data. Use -1 to never evaluate.')\n",
    "flags.DEFINE_integer(\n",
    "    'checkpoint_interval', 50,\n",
    "    'Number of epochs between saving checkpoints. Use -1 to '\n",
    "    'never save checkpoints.')\n",
    "flags.DEFINE_integer('num_bins', 15, 'Number of bins for ECE.')\n",
    "flags.DEFINE_string(\n",
    "    'output_dir', '/home/jupyter/mnist/WRN28-2/M6', 'The directory where the model weights and '\n",
    "                                'training/evaluation summaries are stored.')\n",
    "flags.DEFINE_integer('train_epochs', 200, 'Number of training epochs.')\n",
    "\n",
    "# Accelerator flags.\n",
    "flags.DEFINE_bool('use_gpu', True, 'Whether to run on GPU or otherwise TPU.')\n",
    "flags.DEFINE_bool('use_bfloat16', False, 'Whether to use mixed precision.')\n",
    "flags.DEFINE_integer('num_cores', 8, 'Number of TPU cores or number of GPUs.')\n",
    "flags.DEFINE_string('tpu', None,\n",
    "                    'Name of the TPU. Only used if use_gpu is False.')\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd321a60-34de-4f18-9df7-80aeb9a51d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 2\n",
    "image_shape=[28,28,1]\n",
    "width_multiplier=2\n",
    "num_classes=10\n",
    "output_dir='/home/jupyter/mnist/WRN28-2/M2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595f64e8-9ece-43fb-8a45-b9b731ef418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-29 15:15:44.839611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:44.887711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:44.888572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:44.890615: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-29 15:15:44.891420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:44.892202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:44.893026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:45.435604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:45.436473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:45.437291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-29 15:15:45.438103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10790 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = mnist_model.wide_resnet(\n",
    "    input_shape=[ensemble_size] +\n",
    "                image_shape,\n",
    "    depth=28,\n",
    "    width_multiplier=width_multiplier,\n",
    "    num_classes=num_classes,\n",
    "    ensemble_size=ensemble_size)\n",
    "\n",
    "#model.summary()\n",
    "logging.info('Model input shape: %s', model.input_shape)\n",
    "logging.info('Model output shape: %s', model.output_shape)\n",
    "logging.info('Model number of weights: %s', model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9100518-efbf-4e5a-9862-0aac3ba44298",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD( momentum=0.9, nesterov=True)\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
    "latest_checkpoint = tf.train.latest_checkpoint(output_dir)\n",
    "initial_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fed386d-df76-4a4a-8e6d-f3de0cc2efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f58ae776bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " checkpoint.restore(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6abb76c6-16a2-4acb-9b88-de8ed541e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images, labels = inputs\n",
    "images = tf.tile(\n",
    "    tf.expand_dims(images, 1), [1, FLAGS.ensemble_size, 1, 1, 1])\n",
    "logits = checkpoint.model(images, training=False)\n",
    "if FLAGS.use_bfloat16:\n",
    "    logits = tf.cast(logits, tf.float32)\n",
    "probs = tf.nn.softmax(logits)\n",
    "\n",
    "if dataset_name == 'clean':\n",
    "    per_probs = tf.transpose(probs, perm=[1, 0, 2])\n",
    "    metrics['test/diversity'].add_batch(per_probs)\n",
    "\n",
    "for i in range(FLAGS.ensemble_size):\n",
    "    member_probs = probs[:, i]\n",
    "    member_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, member_probs)\n",
    "    metrics['test/nll_member_{}'.format(i)].update_state(member_loss)\n",
    "    metrics['test/accuracy_member_{}'.format(i)].update_state(\n",
    "        labels, member_probs)\n",
    "\n",
    "# Negative log marginal likelihood computed in a numerically-stable way.\n",
    "labels_tiled = tf.tile(\n",
    "    tf.expand_dims(labels, 1), [1, FLAGS.ensemble_size])\n",
    "log_likelihoods = -tf.keras.losses.sparse_categorical_crossentropy(\n",
    "    labels_tiled, logits, from_logits=True)\n",
    "negative_log_likelihood = tf.reduce_mean(\n",
    "    -tf.reduce_logsumexp(log_likelihoods, axis=[1]) +\n",
    "    tf.math.log(float(FLAGS.ensemble_size)))\n",
    "probs = tf.math.reduce_mean(probs, axis=1)  # marginalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba57381-f7a8-41fa-b58d-553d2c913537",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: The shape of labels (received (20, 1)) should equal the shape of logits except for the last dimension (received (20, 2, 10)).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30594/1392838382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m tf.reduce_mean(tf.reduce_sum(\n\u001b[1;32m      2\u001b[0m                     tf.keras.losses.sparse_categorical_crossentropy(\n\u001b[0;32m----> 3\u001b[0;31m                         labels, logits, from_logits=True), axis=1))\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1737\u001b[0m   \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m   return backend.sparse_categorical_crossentropy(\n\u001b[0;32m-> 1739\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4958\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4959\u001b[0m     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4960\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   4961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4962\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4350\u001b[0m   \"\"\"\n\u001b[1;32m   4351\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4352\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   4353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DAL/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4257\u001b[0m                        \u001b[0;34m\"should equal the shape of logits except for the last \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4258\u001b[0m                        \"dimension (received %s).\" % (labels_static_shape,\n\u001b[0;32m-> 4259\u001b[0;31m                                                      logits.get_shape()))\n\u001b[0m\u001b[1;32m   4260\u001b[0m     \u001b[0;31m# Check if no reshapes are required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape mismatch: The shape of labels (received (20, 1)) should equal the shape of logits except for the last dimension (received (20, 2, 10))."
     ]
    }
   ],
   "source": [
    "tf.reduce_mean(tf.reduce_sum(\n",
    "                    tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                        labels, logits, from_logits=True), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe9d37-a18e-43ba-8ce7-65b5d2204860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42068b-3666-4c75-9bde-5113dade3d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5dbbe-aa12-4b8d-998d-a2e49bbd7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_not_mnist(corruption_name,\n",
    "                   corruption_intensity,\n",
    "                   batch_size,\n",
    "                   use_bfloat16,\n",
    "                   drop_remainder=False,\n",
    "                   normalize=True):\n",
    "  \"\"\"Loads mnist-C dataset.\"\"\"\n",
    "  if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "  corruption = corruption_name #+ '_' + str(corruption_intensity)\n",
    "  def preprocess(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype)\n",
    "    if normalize:\n",
    "      # We use the convention of mean = np.mean(train_images, axis=(0,1,2))\n",
    "      # and std = np.std(train_images, axis=(0,1,2)).\n",
    "      mean = tf.constant([0.1307], dtype=dtype)\n",
    "      std = tf.constant([0.3081], dtype=dtype)\n",
    "      # Previously, std = np.mean(np.std(train_images, axis=(1, 2)), axis=0)\n",
    "      # which gave std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype).\n",
    "      # However, we change convention to use the std over the entire training\n",
    "      # set instead.\n",
    "      image = (image - mean) / std\n",
    "    label = tf.cast(label, dtype)\n",
    "    return image, label\n",
    "\n",
    "  dataset = tfds.load(name='mnist_corrupted/{}'.format(corruption),\n",
    "                      split=tfds.Split.TEST,\n",
    "                      as_supervised=True,\n",
    "                      download=True)\n",
    "  dataset = dataset.map(\n",
    "      preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c1df0b-ea7f-428c-a850-653fae9d19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57dd2502-44df-4546-a3ad-29302fea4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_root = '/home/jupyter/tensorflow_datasets/not_mnist/notMNIST_small'\n",
    "dirs = os.listdir(im_root)\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16, 6))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        dr = random.choice(dirs)\n",
    "        im = random.choice(os.listdir(os.path.join(im_root, dr)))\n",
    "        ax[i, j].imshow(plt.imread(os.path.join(im_root, dr, im)), cmap='gray')\n",
    "        ax[i, j].set_title(dr)\n",
    "        ax[i, j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca068f-6b28-4b7a-81d3-26ab7eaa9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "E\n",
      "D\n",
      "C\n",
      "G\n",
      "F\n",
      "A\n",
      "J\n",
      "H\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "import imghdr\n",
    "dirs = os.listdir(im_root)\n",
    "label_dict = defaultdict()\n",
    "\n",
    "# filenames = tf.constant(['im_01.jpg', 'im_02.jpg', 'im_03.jpg', 'im_04.jpg'])\n",
    "# labels = tf.constant([0, 1, 0, 1])\n",
    "filenames=[]\n",
    "labels=[]\n",
    "images=[]\n",
    "c=0\n",
    "for idx, dr in enumerate(dirs):\n",
    "    print(dr)\n",
    "    label_dict[idx] = dr\n",
    "    ims = os.listdir(os.path.join(im_root, dr))\n",
    "    random.shuffle(ims)\n",
    "    for im in (ims):\n",
    "        # \n",
    "        image_string = tf.io.read_file(os.path.join(im_root, dr, im))\n",
    "        try:\n",
    "            tf.io.decode_image(image_string)\n",
    "        except:\n",
    "            continue\n",
    "        filenames.append(os.path.join(im_root, dr, im))\n",
    "        labels.append(idx)\n",
    "        \n",
    "filenames = tf.constant(filenames)\n",
    "labels = tf.constant(labels) \n",
    "# images = tf.constant(images) \n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "use_bfloat16=True\n",
    "normalize=True\n",
    "\n",
    "if use_bfloat16:\n",
    "    dtype = tf.bfloat16\n",
    "else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "def _parse_function(filename, label):\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.io.decode_image(image_string, dtype=dtype)\n",
    "\n",
    "    # image = tf.image.convert_image_dtype(image_decoded, dtype)\n",
    "    if normalize:\n",
    "      # We use the convention of mean = np.mean(train_images, axis=(0,1,2))\n",
    "      # and std = np.std(train_images, axis=(0,1,2)).\n",
    "      mean = tf.constant([0.1307], dtype=dtype)\n",
    "      std = tf.constant([0.3081], dtype=dtype)\n",
    "      # Previously, std = np.mean(np.std(train_images, axis=(1, 2)), axis=0)\n",
    "      # which gave std = tf.constant([0.2023, 0.1994, 0.2010], dtype=dtype).\n",
    "      # However, we change convention to use the std over the entire training\n",
    "      # set instead.\n",
    "      image = (image - mean) / std\n",
    "    label = tf.cast(label, dtype)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e15986-d31a-4136-9db7-66fc4a347aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9], dtype=bfloat16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4043e4f-c5d1-4d9b-8ce3-687ee54f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(dataset.as_numpy_iterator())[-10:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2a04191-42fa-43aa-aa81-9db3937d0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(dataset.as_numpy_iterator())\n",
    "dataset\n",
    "filenames[0]\n",
    "f=\"Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\"\n",
    "image_string = tf.io.read_file(filenames[0])\n",
    "image_string\n",
    "image = tf.io.decode_png(image_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5a85879-9909-4d90-b057-1d4f5dc2799c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((None, None, 1), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = tf.constant(['im_01.jpg', 'im_02.jpg', 'im_03.jpg', 'im_04.jpg'])\n",
    "labels = tf.constant([0, 1, 0, 1])\n",
    "\n",
    "# step 2: create a dataset returning slices of `filenames`\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "# step 3: parse every image in the dataset using `map`\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_png(image_string, channels=1)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "# dataset = dataset.batch(2)\n",
    "dataset\n",
    "# step 4: create iterator and final input tensor\n",
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# images, labels = iterator.get_next()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python [conda env:DAL]",
   "language": "python",
   "name": "conda-env-DAL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
